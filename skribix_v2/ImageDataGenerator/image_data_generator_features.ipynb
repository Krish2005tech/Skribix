{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff66120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 11:22:23.506798: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 11:22:23.759521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744177943.872681    7392 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744177943.904297    7392 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744177944.107649    7392 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177944.107725    7392 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177944.107728    7392 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177944.107732    7392 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-09 11:22:24.132348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 15 classes.\n",
      "Total samples: 1200\n",
      "Saved preprocessed images and labels to preprocessed_images.npy and preprocessed_labels.npy\n",
      "Saved class indices mapping to class_indices.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data directory and parameters\n",
    "data_dir = \"../sketches\"  \n",
    "target_size = (128, 128)\n",
    "batch_size = 64\n",
    "\n",
    "# Create an ImageDataGenerator instance with the desired preprocessing and augmentation.\n",
    "# Here, we'll use the custom preprocessing_function from earlier to do resizing, inversion, and normalization.\n",
    "def preprocessing_function(img):\n",
    "    # For an input image (as a NumPy array) with shape (H, W, 3) or (H, W),\n",
    "    # convert to grayscale (if needed), resize to 128x128 using bilinear interpolation,\n",
    "    # invert pixel values so that zeros correspond to background (white), and rescale to [0,1]\n",
    "    import cv2\n",
    "    if img.ndim == 3 and img.shape[-1] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    img_inverted = 255 - img_resized  # invert image\n",
    "    img_norm = img_inverted.astype(\"float32\") / 255.0\n",
    "    # Expand dims to create shape (128,128,1)\n",
    "    return np.expand_dims(img_norm, axis=-1)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocessing_function,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # if you also want a validation split\n",
    ")\n",
    "\n",
    "# Create a generator that reads from the data directory.\n",
    "# Here, \"categorical\" mode assumes that each subfolder is a class and creates one-hot labels.\n",
    "generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Option 1: Save the raw processed images and labels\n",
    "\n",
    "# Get the number of samples\n",
    "num_samples = generator.samples\n",
    "print(\"Total samples:\", num_samples)\n",
    "\n",
    "# Preallocate arrays for images and labels\n",
    "# Images will be in shape (num_samples, 128, 128, 1)\n",
    "X = np.zeros((num_samples, target_size[0], target_size[1], 1), dtype=\"float32\")\n",
    "y = np.zeros((num_samples, len(generator.class_indices)), dtype=\"float32\")\n",
    "\n",
    "# Iterate over the generator and collect the data\n",
    "i = 0\n",
    "for batch in generator:\n",
    "    batch_x, batch_y = batch  # unpack images and labels\n",
    "    batch_size_actual = batch_x.shape[0]\n",
    "    X[i:i+batch_size_actual] = batch_x\n",
    "    y[i:i+batch_size_actual] = batch_y\n",
    "    i += batch_size_actual\n",
    "    if i >= num_samples:\n",
    "        break\n",
    "\n",
    "# Save the arrays to disk for easy access (others can load these without rerunning augmentation)\n",
    "np.save(\"preprocessed_images.npy\", X)\n",
    "np.save(\"preprocessed_labels.npy\", y)\n",
    "print(\"Saved preprocessed images and labels to preprocessed_images.npy and preprocessed_labels.npy\")\n",
    "\n",
    "# Option 2: You may also want to save the generator's class indices mapping for reference:\n",
    "np.save(\"class_indices.npy\", generator.class_indices)\n",
    "print(\"Saved class indices mapping to class_indices.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdd8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"preprocessed_images.npy\")\n",
    "y = np.load(\"preprocessed_labels.npy\")\n",
    "class_indices = np.load(\"class_indices.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388e7de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
