{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting dataset normalization and processing...\n",
            "\n",
            "Total classes found: 15\n",
            "\n",
            "[1/15] Processed 'airplane' - 80 images copied.\n",
            "[2/15] Processed 'book' - 80 images copied.\n",
            "[3/15] Processed 'cup' - 80 images copied.\n",
            "[4/15] Processed 'envelope' - 80 images copied.\n",
            "[5/15] Processed 'fan' - 80 images copied.\n",
            "[6/15] Processed 'fork' - 80 images copied.\n",
            "[7/15] Processed 'hat' - 80 images copied.\n",
            "[8/15] Processed 'key' - 80 images copied.\n",
            "[9/15] Processed 'laptop' - 80 images copied.\n",
            "[10/15] Processed 'leaf' - 80 images copied.\n",
            "[11/15] Processed 'moon' - 80 images copied.\n",
            "[12/15] Processed 'pizza' - 80 images copied.\n",
            "[13/15] Processed 't-shirt' - 80 images copied.\n",
            "[14/15] Processed 'traffic light' - 80 images copied.\n",
            "[15/15] Processed 'wineglass' - 80 images copied.\n",
            "\n",
            "Dataset processing complete.\n",
            "Total classes processed: 15\n",
            "Total images copied: 1200\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "source_dir = r\"C:\\Users\\YASHRAJ\\OneDrive\\文档\\Skribix-copy\\skribix_v2\\sketches\"\n",
        "dest_dir = r\"C:\\Users\\YASHRAJ\\Last_dataset\\normalised\"\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "# Get all class folders\n",
        "all_classes = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n",
        "\n",
        "print(\"Starting dataset normalization and processing...\\n\")\n",
        "print(f\"Total classes found: {len(all_classes)}\\n\")\n",
        "\n",
        "total_images_copied = 0\n",
        "\n",
        "for idx, class_name in enumerate(sorted(all_classes), start=1):\n",
        "    class_source_path = os.path.join(source_dir, class_name)\n",
        "    class_dest_path = os.path.join(dest_dir, class_name)\n",
        "    os.makedirs(class_dest_path, exist_ok=True)\n",
        "\n",
        "    images = sorted(os.listdir(class_source_path))\n",
        "    \n",
        "    for img_name in images:\n",
        "        src_path = os.path.join(class_source_path, img_name)\n",
        "        dest_path = os.path.join(class_dest_path, img_name)\n",
        "        shutil.copy(src_path, dest_path)\n",
        "        total_images_copied += 1\n",
        "\n",
        "    print(f\"[{idx}/{len(all_classes)}] Processed '{class_name}' - {len(images)} images copied.\")\n",
        "\n",
        "print(\"\\nDataset processing complete.\")\n",
        "print(f\"Total classes processed: {len(all_classes)}\")\n",
        "print(f\"Total images copied: {total_images_copied}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting dataset splitting...\n",
            "\n",
            "Split ratios - Train: 70%, Validation: 10%, Test: 20%\n",
            "\n",
            "[1] airplane: 56 train, 8 val, 16 test\n",
            "[2] book: 56 train, 8 val, 16 test\n",
            "[3] cup: 56 train, 8 val, 16 test\n",
            "[4] envelope: 56 train, 8 val, 16 test\n",
            "[5] fan: 56 train, 8 val, 16 test\n",
            "[6] fork: 56 train, 8 val, 16 test\n",
            "[7] hat: 56 train, 8 val, 16 test\n",
            "[8] key: 56 train, 8 val, 16 test\n",
            "[9] laptop: 56 train, 8 val, 16 test\n",
            "[10] leaf: 56 train, 8 val, 16 test\n",
            "[11] moon: 56 train, 8 val, 16 test\n",
            "[12] pizza: 56 train, 8 val, 16 test\n",
            "[13] t-shirt: 56 train, 8 val, 16 test\n",
            "[14] traffic light: 56 train, 8 val, 16 test\n",
            "[15] wineglass: 56 train, 8 val, 16 test\n",
            "\n",
            "Dataset splitting complete.\n",
            "Total classes processed: 15\n",
            "Total images -> Train: 840, Validation: 120, Test: 240\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "NORMALIZED_PATH = r\"C:\\Users\\YASHRAJ\\Last_dataset\\normalised\"\n",
        "DATASET_SPLIT_PATH = r\"C:\\Users\\YASHRAJ\\Last_dataset\\split\"\n",
        "\n",
        "# Define split percentages\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.2\n",
        "\n",
        "# Create dataset split directories\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    split_path = os.path.join(DATASET_SPLIT_PATH, split)\n",
        "    os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "print(\"Starting dataset splitting...\\n\")\n",
        "print(f\"Split ratios - Train: {int(TRAIN_RATIO*100)}%, Validation: {int(VAL_RATIO*100)}%, Test: {int(TEST_RATIO*100)}%\\n\")\n",
        "\n",
        "total_classes = 0\n",
        "total_train = 0\n",
        "total_val = 0\n",
        "total_test = 0\n",
        "\n",
        "# Iterate through each class\n",
        "for class_name in sorted(os.listdir(NORMALIZED_PATH)):\n",
        "    class_source_path = os.path.join(NORMALIZED_PATH, class_name)\n",
        "    \n",
        "    if not os.path.isdir(class_source_path):\n",
        "        continue  # Skip non-directory files\n",
        "\n",
        "    images = sorted(os.listdir(class_source_path))\n",
        "    random.shuffle(images)\n",
        "\n",
        "    train_count = int(len(images) * TRAIN_RATIO)\n",
        "    val_count = int(len(images) * VAL_RATIO)\n",
        "\n",
        "    train_images = images[:train_count]\n",
        "    val_images = images[train_count:train_count + val_count]\n",
        "    test_images = images[train_count + val_count:]\n",
        "\n",
        "    # Update totals\n",
        "    total_classes += 1\n",
        "    total_train += len(train_images)\n",
        "    total_val += len(val_images)\n",
        "    total_test += len(test_images)\n",
        "\n",
        "    # Copy files\n",
        "    for split, split_images in zip([\"train\", \"val\", \"test\"], [train_images, val_images, test_images]):\n",
        "        split_class_path = os.path.join(DATASET_SPLIT_PATH, split, class_name)\n",
        "        os.makedirs(split_class_path, exist_ok=True)\n",
        "\n",
        "        for img_name in split_images:\n",
        "            src_img_path = os.path.join(class_source_path, img_name)\n",
        "            dest_img_path = os.path.join(split_class_path, img_name)\n",
        "            shutil.copy(src_img_path, dest_img_path)\n",
        "\n",
        "    print(f\"[{total_classes}] {class_name}: {len(train_images)} train, {len(val_images)} val, {len(test_images)} test\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\nDataset splitting complete.\")\n",
        "print(f\"Total classes processed: {total_classes}\")\n",
        "print(f\"Total images -> Train: {total_train}, Validation: {total_val}, Test: {total_test}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "\n",
            " Loading dataset...\n",
            "\n",
            "Found 840 images belonging to 15 classes.\n",
            "Found 120 images belonging to 15 classes.\n",
            "\n",
            " Building CNN model...\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "\n",
            " Starting training...\n",
            "\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From c:\\Users\\Yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "27/27 [==============================] - ETA: 0s - loss: 2.8560 - accuracy: 0.0702\n",
            "Epoch 1: val_accuracy improved from -inf to 0.11667, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Yashraj\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 20s 696ms/step - loss: 2.8560 - accuracy: 0.0702 - val_loss: 2.6898 - val_accuracy: 0.1167 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 2.6476 - accuracy: 0.1393\n",
            "Epoch 2: val_accuracy did not improve from 0.11667\n",
            "27/27 [==============================] - 18s 665ms/step - loss: 2.6476 - accuracy: 0.1393 - val_loss: 2.3474 - val_accuracy: 0.1083 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 2.0823 - accuracy: 0.3131\n",
            "Epoch 3: val_accuracy improved from 0.11667 to 0.47500, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "27/27 [==============================] - 18s 665ms/step - loss: 2.0823 - accuracy: 0.3131 - val_loss: 1.6931 - val_accuracy: 0.4750 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.6229 - accuracy: 0.4738\n",
            "Epoch 4: val_accuracy improved from 0.47500 to 0.56667, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "27/27 [==============================] - 19s 704ms/step - loss: 1.6229 - accuracy: 0.4738 - val_loss: 1.7106 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.4508 - accuracy: 0.5488\n",
            "Epoch 5: val_accuracy improved from 0.56667 to 0.61667, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "27/27 [==============================] - 18s 667ms/step - loss: 1.4508 - accuracy: 0.5488 - val_loss: 1.4012 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2385 - accuracy: 0.6190\n",
            "Epoch 6: val_accuracy did not improve from 0.61667\n",
            "27/27 [==============================] - 18s 670ms/step - loss: 1.2385 - accuracy: 0.6190 - val_loss: 1.4799 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.0917 - accuracy: 0.6357\n",
            "Epoch 7: val_accuracy improved from 0.61667 to 0.65833, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "27/27 [==============================] - 18s 678ms/step - loss: 1.0917 - accuracy: 0.6357 - val_loss: 1.3486 - val_accuracy: 0.6583 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.6857\n",
            "Epoch 8: val_accuracy improved from 0.65833 to 0.69167, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "27/27 [==============================] - 18s 663ms/step - loss: 1.0692 - accuracy: 0.6857 - val_loss: 1.1073 - val_accuracy: 0.6917 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.9777 - accuracy: 0.6881\n",
            "Epoch 9: val_accuracy did not improve from 0.69167\n",
            "27/27 [==============================] - 17s 640ms/step - loss: 0.9777 - accuracy: 0.6881 - val_loss: 1.3791 - val_accuracy: 0.6917 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.8395 - accuracy: 0.7345\n",
            "Epoch 10: val_accuracy did not improve from 0.69167\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "27/27 [==============================] - 17s 642ms/step - loss: 0.8395 - accuracy: 0.7345 - val_loss: 1.2838 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.7617 - accuracy: 0.7452\n",
            "Epoch 11: val_accuracy improved from 0.69167 to 0.73333, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "27/27 [==============================] - 18s 655ms/step - loss: 0.7617 - accuracy: 0.7452 - val_loss: 1.2063 - val_accuracy: 0.7333 - lr: 5.0000e-04\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.7750\n",
            "Epoch 12: val_accuracy improved from 0.73333 to 0.74167, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "27/27 [==============================] - 18s 681ms/step - loss: 0.6833 - accuracy: 0.7750 - val_loss: 1.1905 - val_accuracy: 0.7417 - lr: 5.0000e-04\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7845\n",
            "Epoch 13: val_accuracy improved from 0.74167 to 0.75000, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "27/27 [==============================] - 18s 648ms/step - loss: 0.6352 - accuracy: 0.7845 - val_loss: 1.1877 - val_accuracy: 0.7500 - lr: 2.5000e-04\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.8036\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "27/27 [==============================] - 17s 624ms/step - loss: 0.6193 - accuracy: 0.8036 - val_loss: 1.2708 - val_accuracy: 0.7333 - lr: 2.5000e-04\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.8131\n",
            "Epoch 15: val_accuracy did not improve from 0.75000\n",
            "27/27 [==============================] - 17s 631ms/step - loss: 0.5980 - accuracy: 0.8131 - val_loss: 1.2511 - val_accuracy: 0.7417 - lr: 1.2500e-04\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7988\n",
            "Epoch 16: val_accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "27/27 [==============================] - 17s 636ms/step - loss: 0.5986 - accuracy: 0.7988 - val_loss: 1.2444 - val_accuracy: 0.7333 - lr: 1.2500e-04\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.8048\n",
            "Epoch 17: val_accuracy improved from 0.75000 to 0.75833, saving model to C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "27/27 [==============================] - 18s 665ms/step - loss: 0.6228 - accuracy: 0.8048 - val_loss: 1.1609 - val_accuracy: 0.7583 - lr: 6.2500e-05\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.8333\n",
            "Epoch 18: val_accuracy did not improve from 0.75833\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "27/27 [==============================] - 17s 627ms/step - loss: 0.5434 - accuracy: 0.8333 - val_loss: 1.2021 - val_accuracy: 0.7500 - lr: 6.2500e-05\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8321\n",
            "Epoch 19: val_accuracy did not improve from 0.75833\n",
            "27/27 [==============================] - 17s 627ms/step - loss: 0.5425 - accuracy: 0.8321 - val_loss: 1.1870 - val_accuracy: 0.7583 - lr: 3.1250e-05\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.8214\n",
            "Epoch 20: val_accuracy did not improve from 0.75833\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "27/27 [==============================] - 17s 621ms/step - loss: 0.5688 - accuracy: 0.8214 - val_loss: 1.2290 - val_accuracy: 0.7500 - lr: 3.1250e-05\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5484 - accuracy: 0.8262\n",
            "Epoch 21: val_accuracy did not improve from 0.75833\n",
            "27/27 [==============================] - 17s 625ms/step - loss: 0.5484 - accuracy: 0.8262 - val_loss: 1.2274 - val_accuracy: 0.7583 - lr: 1.5625e-05\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.8202\n",
            "Epoch 22: val_accuracy did not improve from 0.75833\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "27/27 [==============================] - 17s 635ms/step - loss: 0.5734 - accuracy: 0.8202 - val_loss: 1.2042 - val_accuracy: 0.7583 - lr: 1.5625e-05\n",
            "Epoch 22: early stopping\n",
            "\n",
            " Training complete!\n",
            " Best Model saved at: C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            " Best Training Accuracy: 83.33%\n",
            " Best Validation Accuracy: 75.83%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Paths\n",
        "DATASET_SPLIT_PATH = r\"C:\\Users\\YASHRAJ\\Last_dataset\\split\"\n",
        "MODEL_SAVE_PATH = r\"C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\"\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "\n",
        "# Image Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    zoom_range=0.05,\n",
        "    shear_range=0.05\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Load datasets\n",
        "print(\"\\n Loading dataset...\\n\")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(DATASET_SPLIT_PATH, \"train\"),\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    os.path.join(DATASET_SPLIT_PATH, \"val\"),\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False,\n",
        "    classes=train_generator.class_indices\n",
        ")\n",
        "\n",
        "# CNN Model\n",
        "print(\"\\n Building CNN model...\\n\")\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 1)),\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=MODEL_SAVE_PATH,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "earlystop_cb = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr_cb = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model with clean logging\n",
        "print(\"\\n Starting training...\\n\")\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[checkpoint_cb, earlystop_cb, reduce_lr_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "\n",
        "# Print training summary\n",
        "best_val_acc = max(history.history['val_accuracy'])\n",
        "best_train_acc = max(history.history['accuracy'])\n",
        "\n",
        "print(\"\\n Training complete!\")\n",
        "print(f\" Best Model saved at: {MODEL_SAVE_PATH}\")\n",
        "print(f\" Best Training Accuracy: {best_train_acc * 100:.2f}%\")\n",
        "print(f\" Best Validation Accuracy: {best_val_acc * 100:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded model from: C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\n",
            "Found 240 images belonging to 15 classes.\n",
            " Predicting on test data...\n",
            "8/8 [==============================] - 1s 129ms/step\n",
            "\n",
            " Test Accuracy: 75.00%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# --- Paths ---\n",
        "MODEL_PATH = r\"C:\\Users\\YASHRAJ\\Last_CNN\\FinalCNN_bestepoch_model.h5\"\n",
        "DATASET_SPLIT_PATH = \"C:/Users/YASHRAJ/Last_dataset/split\"\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Load Model ---\n",
        "model = load_model(MODEL_PATH)\n",
        "print(\" Loaded model from:\", MODEL_PATH)\n",
        "\n",
        "# --- Data Generator (No Augmentation) ---\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# --- Create Test Generator ---\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(DATASET_SPLIT_PATH, \"test\"),\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Important: Keep shuffle=False for accurate evaluation\n",
        ")\n",
        "\n",
        "# --- Get ground truth ---\n",
        "y_true = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# --- Predict ---\n",
        "print(\" Predicting on test data...\")\n",
        "y_pred = model.predict(test_generator, verbose=1)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# --- Accuracy ---\n",
        "test_acc = np.mean(y_pred_classes == y_true)\n",
        "print(f\"\\n Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
