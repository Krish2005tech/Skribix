{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a77e11",
   "metadata": {},
   "source": [
    "### Extracting features from 1200 images locally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9216091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6cf9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Image Preprocessing and Local Descriptor Extraction\n",
    "# ----------------------------\n",
    "\n",
    "def preprocess_image(image_path, size=256):\n",
    "    \"\"\"\n",
    "    Load an image in grayscale and resize it to size x size.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot load image: {image_path}\")\n",
    "    img_resized = cv2.resize(img, (size, size))\n",
    "    return img_resized.astype(np.float32)\n",
    "\n",
    "def compute_gradients(image):\n",
    "    \"\"\"\n",
    "    Compute image gradients using the Sobel operator.\n",
    "    (Gaussian derivatives can be used for more robustness.)\n",
    "    \"\"\"\n",
    "    grad_x = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    orientation = np.arctan2(grad_y, grad_x)\n",
    "    orientation = np.mod(orientation, np.pi)  # Map angles to [0, Ï€)\n",
    "    return magnitude, orientation\n",
    "\n",
    "def extract_local_descriptors(image, grid_size=(28, 28), patch_size_ratio=0.125,\n",
    "                              num_spatial_bins=4, num_orientation_bins=4):\n",
    "    \"\"\"\n",
    "    For each patch (sampled on a grid) in the image, subdivide it into\n",
    "    (num_spatial_bins x num_spatial_bins) cells and compute a histogram of \n",
    "    gradient orientations (with num_orientation_bins bins) for each cell.\n",
    "    Concatenate the histograms from all cells to yield a 64-dimensional descriptor.\n",
    "    Returns an array of descriptors (one per patch).\n",
    "    \"\"\"\n",
    "    magnitude, orientation = compute_gradients(image)\n",
    "    h, w = image.shape\n",
    "    descriptors = []\n",
    "    # Generate grid points (centers) for patches\n",
    "    xs = np.linspace(0, w-1, grid_size[1], dtype=int)\n",
    "    ys = np.linspace(0, h-1, grid_size[0], dtype=int)\n",
    "    patch_size = int(patch_size_ratio * w)  # e.g., ~32 pixels for a 256x256 image\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    for y in ys:\n",
    "        for x in xs:\n",
    "            # Define patch boundaries (with border checks)\n",
    "            x1 = max(x - half_patch, 0)\n",
    "            x2 = min(x + half_patch, w)\n",
    "            y1 = max(y - half_patch, 0)\n",
    "            y2 = min(y + half_patch, h)\n",
    "            patch_mag = magnitude[y1:y2, x1:x2]\n",
    "            patch_orient = orientation[y1:y2, x1:x2]\n",
    "            # Determine cell sizes within the patch\n",
    "            cell_h = (y2 - y1) // num_spatial_bins\n",
    "            cell_w = (x2 - x1) // num_spatial_bins\n",
    "            descriptor = []\n",
    "            # Iterate over cells\n",
    "            for i in range(num_spatial_bins):\n",
    "                for j in range(num_spatial_bins):\n",
    "                    cy1 = y1 + i * cell_h\n",
    "                    cy2 = cy1 + cell_h\n",
    "                    cx1 = x1 + j * cell_w\n",
    "                    cx2 = cx1 + cell_w\n",
    "                    # Extract cell region\n",
    "                    cell_orient = patch_orient[cy1 - y1:cy2 - y1, cx1 - x1:cx2 - x1]\n",
    "                    cell_mag = patch_mag[cy1 - y1:cy2 - y1, cx1 - x1:cx2 - x1]\n",
    "                    # Compute histogram for cell\n",
    "                    hist, _ = np.histogram(cell_orient, bins=num_orientation_bins, \n",
    "                                           range=(0, np.pi), weights=cell_mag)\n",
    "                    descriptor.extend(hist)\n",
    "            descriptor = np.array(descriptor, dtype=np.float32)\n",
    "            norm_val = np.linalg.norm(descriptor)\n",
    "            if norm_val > 0:\n",
    "                descriptor /= norm_val\n",
    "            descriptors.append(descriptor)\n",
    "    return np.array(descriptors)  # Shape: (num_patches, 64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ce4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Step 2: Build Visual Vocabulary using K-Means\n",
    "# ----------------------------\n",
    "\n",
    "def gather_all_descriptors(dataset_folder):\n",
    "    \"\"\"\n",
    "    Iterate over all images in the dataset folder.\n",
    "    Assumes that dataset_folder has subfolders for each category.\n",
    "    Returns:\n",
    "      - all_descriptors: an array of all local descriptors extracted.\n",
    "      - image_paths: a list of image paths (for later feature extraction).\n",
    "      - labels: a list of integer labels corresponding to each image.\n",
    "    \"\"\"\n",
    "    all_descriptors = []\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    categories = sorted(os.listdir(dataset_folder))\n",
    "    # You may want to map category names to integer labels:\n",
    "    label_dict = {cat: idx for idx, cat in enumerate(categories)}\n",
    "    \n",
    "    for cat in categories:\n",
    "        cat_path = os.path.join(dataset_folder, cat)\n",
    "        if not os.path.isdir(cat_path):\n",
    "            continue\n",
    "        # Process common image file types\n",
    "        for ext in ['*.jpg', '*.png', '*.jpeg', '*.bmp']:\n",
    "            files = glob.glob(os.path.join(cat_path, ext))\n",
    "            for file in files:\n",
    "                try:\n",
    "                    img = preprocess_image(file)\n",
    "                    desc = extract_local_descriptors(img)\n",
    "                    # Append all descriptors from this image\n",
    "                    all_descriptors.append(desc)\n",
    "                    image_paths.append(file)\n",
    "                    labels.append(label_dict[cat])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "    # Concatenate all descriptors (each image returns an array of shape (num_patches, 64))\n",
    "    all_descriptors = np.vstack(all_descriptors)\n",
    "    return all_descriptors, image_paths, labels, label_dict\n",
    "\n",
    "def build_vocabulary(all_descriptors, vocab_size=500, save_path='vocabulary.npy'):\n",
    "    \"\"\"\n",
    "    Learn a visual vocabulary by applying k-means to the collected descriptors.\n",
    "    Returns the vocabulary (a NumPy array of shape (vocab_size, descriptor_dim)).\n",
    "    \"\"\"\n",
    "    print(\"Clustering descriptors to build vocabulary...\")\n",
    "    kmeans = KMeans(n_clusters=vocab_size, random_state=42, n_init=10)\n",
    "    kmeans.fit(all_descriptors)\n",
    "    vocabulary = kmeans.cluster_centers_\n",
    "    np.save(save_path, vocabulary)\n",
    "    print(f\"Vocabulary saved to {save_path}\")\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e792600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Step 3: Compute Global Image Feature (Histogram of Visual Words)\n",
    "# ----------------------------\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def soft_quantize_descriptors(descriptors, vocabulary, sigma=0.3):\n",
    "    \"\"\"\n",
    "    For each descriptor, compute Gaussian weighted contributions to each vocabulary center,\n",
    "    then sum up contributions into a histogram.\n",
    "    \"\"\"\n",
    "    distances = cdist(descriptors, vocabulary, metric='euclidean')\n",
    "    # Compute weights using a Gaussian kernel\n",
    "    weights = np.exp(-distances**2 / (2 * sigma**2))\n",
    "    # Normalize weights for each descriptor\n",
    "    weights /= weights.sum(axis=1, keepdims=True)\n",
    "    # Sum contributions over all descriptors to obtain histogram\n",
    "    hist = weights.sum(axis=0)\n",
    "    if hist.sum() > 0:\n",
    "        hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "def extract_image_feature(image, vocabulary):\n",
    "    \"\"\"\n",
    "    For a given image, extract local descriptors and compute a global 500-D feature \n",
    "    vector by quantizing the descriptors with the visual vocabulary.\n",
    "    \"\"\"\n",
    "    descriptors = extract_local_descriptors(image)\n",
    "    feature_vector = soft_quantize_descriptors(descriptors, vocabulary)\n",
    "    return feature_vector\n",
    "\n",
    "def extract_features_dataset(dataset_folder, vocabulary):\n",
    "    \"\"\"\n",
    "    Process all images in the dataset folder, extract their global features,\n",
    "    and return:\n",
    "      - features: an array of shape (num_images, vocab_size)\n",
    "      - labels: a list of integer labels corresponding to each image.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    categories = sorted(os.listdir(dataset_folder))\n",
    "    label_dict = {cat: idx for idx, cat in enumerate(categories)}\n",
    "    \n",
    "    for cat in categories:\n",
    "        cat_path = os.path.join(dataset_folder, cat)\n",
    "        if not os.path.isdir(cat_path):\n",
    "            continue\n",
    "        for ext in ['*.jpg', '*.png']:\n",
    "            files = glob.glob(os.path.join(cat_path, ext))\n",
    "            for file in files:\n",
    "                try:\n",
    "                    img = preprocess_image(file)\n",
    "                    feat = extract_image_feature(img, vocabulary)\n",
    "                    features.append(feat)\n",
    "                    labels.append(label_dict[cat])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "    features = np.array(features)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f2c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting local descriptors from dataset images...\n",
      "Collected 940800 descriptors from 1200 images.\n",
      "Clustering descriptors to build vocabulary...\n",
      "Vocabulary saved to vocabulary.npy\n",
      "Extracting global features for each image...\n",
      "Extracted features shape: (1200, 500)\n",
      "Features and labels saved as 'image_features.npy' and 'image_labels.npy'.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Main Function for Feature Extraction Pipeline\n",
    "# ----------------------------\n",
    "\n",
    "def main():\n",
    "    dataset_folder = '../sketches'\n",
    "    \n",
    "    # gathering all local descriptors from the dataset\n",
    "    print(\"Extracting local descriptors from dataset images...\")\n",
    "    all_descriptors, image_paths, image_labels, label_dict = gather_all_descriptors(dataset_folder)\n",
    "    print(f\"Collected {all_descriptors.shape[0]} descriptors from {len(image_paths)} images.\")\n",
    "    \n",
    "    # building the visual vocabulary\n",
    "    vocab_path = 'vocabulary.npy'\n",
    "    if os.path.exists(vocab_path):\n",
    "        print(f\"Loading existing vocabulary from {vocab_path}\")\n",
    "        vocabulary = np.load(vocab_path)\n",
    "    else:\n",
    "        vocabulary = build_vocabulary(all_descriptors, vocab_size=500, save_path=vocab_path)\n",
    "    \n",
    "    # computing the global feature vector for each image\n",
    "    print(\"Extracting global features for each image...\")\n",
    "    features, labels = extract_features_dataset(dataset_folder, vocabulary)\n",
    "    print(f\"Extracted features shape: {features.shape}\")\n",
    "    \n",
    "    # saving features and labels for training your recognition model\n",
    "    np.save('image_features.npy', features)\n",
    "    np.save('image_labels.npy', np.array(labels))\n",
    "    print(\"Features and labels saved as 'image_features.npy' and 'image_labels.npy'.\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "051ed03f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sketches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Recreate the label dictionary based on the dataset folder structure\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dataset_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msketches\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(dataset_folder))\n\u001b[1;32m     10\u001b[0m label_dict \u001b[38;5;241m=\u001b[39m {cat: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, cat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(categories)}\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Reverse the label dictionary to map labels back to category names\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sketches'"
     ]
    }
   ],
   "source": [
    "dataset_folder = '../sketches'\n",
    "\n",
    "# Load the saved features and labels\n",
    "features = np.load('image_features.npy')\n",
    "labels = np.load('image_labels.npy')\n",
    "\n",
    "# Recreate the label dictionary based on the dataset folder structure\n",
    "dataset_folder = 'sketches'\n",
    "categories = sorted(os.listdir(dataset_folder))\n",
    "label_dict = {cat: idx for idx, cat in enumerate(categories)}\n",
    "\n",
    "# Reverse the label dictionary to map labels back to category names\n",
    "label_dict_reverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# Find the first image of each category and display its feature array\n",
    "first_image_features = {}\n",
    "for label in np.unique(labels):\n",
    "    category_name = label_dict_reverse[label]\n",
    "    first_image_index = np.where(labels == label)[0][0]\n",
    "    first_image_features[category_name] = features[first_image_index]\n",
    "\n",
    "# Display the feature arrays for the first image of each category\n",
    "for category, feature_array in first_image_features.items():\n",
    "    print(f\"Category: {category}, Feature Array: {feature_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa782f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
