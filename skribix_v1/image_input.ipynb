{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 21:07:03.982915: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-05 21:07:04.015767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743867424.052454   99236 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743867424.064363   99236 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743867424.095295   99236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743867424.095365   99236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743867424.095370   99236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743867424.095374   99236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-05 21:07:04.105230: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def load_extraction_params(mat_file_path):\n",
    "    \"\"\"\n",
    "    Optionally load any parameters from your .mat file that are needed\n",
    "    to perform feature extraction. Adjust this function according to your file's structure.\n",
    "    \"\"\"\n",
    "    mat_contents = sio.loadmat(mat_file_path)\n",
    "    # For example, if the mat file contains a structure with parameters:\n",
    "    # params = mat_contents['params']\n",
    "    # return params\n",
    "    # If not needed, simply return None.\n",
    "    return None\n",
    "\n",
    "def extract_features(image, extraction_params=None):\n",
    "    \"\"\"\n",
    "    Extract 500 features from the image. The code below is a placeholder:\n",
    "    you must modify it so that it exactly replicates the extraction routine\n",
    "    (including any smoothing, normalization, etc.) that you applied when building\n",
    "    your feature matrix from the .mat file.\n",
    "    \"\"\"\n",
    "    # Example using HOG features (adjust parameters as needed)\n",
    "    # Resize image to a fixed size (ensure that this is consistent with your training extraction)\n",
    "    resized = cv2.resize(image, (64, 64))\n",
    "    \n",
    "    # Initialize HOG descriptor with chosen parameters.\n",
    "    hog = cv2.HOGDescriptor(_winSize=(64, 64),\n",
    "                            _blockSize=(16, 16),\n",
    "                            _blockStride=(8, 8),\n",
    "                            _cellSize=(8, 8),\n",
    "                            _nbins=9)\n",
    "    hog_features = hog.compute(resized)\n",
    "    hog_features = hog_features.flatten()\n",
    "    \n",
    "    # Adjust the length of the feature vector to be exactly 500.\n",
    "    if hog_features.shape[0] > 500:\n",
    "        features = hog_features[:500]\n",
    "    elif hog_features.shape[0] < 500:\n",
    "        # Pad with zeros if fewer than 500 features are available.\n",
    "        pad = np.zeros(500 - hog_features.shape[0])\n",
    "        features = np.concatenate([hog_features, pad])\n",
    "    else:\n",
    "        features = hog_features\n",
    "\n",
    "    return features\n",
    "\n",
    "def load_pretrained_model(model_path):\n",
    "    \"\"\"\n",
    "    Load the pre-trained model from the provided model file.\n",
    "    Adjust this function if you are using another framework.\n",
    "    \"\"\"\n",
    "    model = load_model(model_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --image IMAGE --model MODEL\n",
      "                             [--params PARAMS]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --image, --model\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Extract features from a test image and predict its class.\")\n",
    "    parser.add_argument('--image', required=True, help=\"sketches/airplane/1.png\")\n",
    "    parser.add_argument('--model', required=True, help=\"best_ann_model.h5\")\n",
    "    parser.add_argument('--params', default=\"features_shog_smooth.mat\", help=\"feature_extraction/features_shog_smooth.mat\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load extraction parameters if necessary\n",
    "    extraction_params = load_extraction_params(args.params)\n",
    "\n",
    "    # Load and validate the test image.\n",
    "    image = cv2.imread(args.image)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not load image from\", args.image)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Extract features from the image.\n",
    "    features = extract_features(image, extraction_params)\n",
    "    # Reshape features to match model input shape (assumes model expects a 2D array, e.g., [batch, features])\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "\n",
    "    # Load the pre-trained model.\n",
    "    model = load_pretrained_model(args.model)\n",
    "\n",
    "    # Predict the class of the image.\n",
    "    prediction = model.predict(features)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    print(\"Predicted class:\", predicted_class[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
