{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:7001\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jyoti\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "# from flask_cors import CORS\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# import base64\n",
    "# import io\n",
    "# from PIL import Image\n",
    "# from joblib import dump, load\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import joblib\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from joblib import dump, load\n",
    "import base64\n",
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# # Placeholder for the image preprocessing function\n",
    "# def img_preprocessing(image):\n",
    "#     # You will define this function later\n",
    "#     pass\n",
    "\n",
    "# # Load the model (ensure the .h5 file is in the correct path)\n",
    "# model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Image Preprocessing and Local Descriptor Extraction\n",
    "# ----------------------------\n",
    "\n",
    "def base64_to_image(base64_str,size=256):\n",
    "    \"\"\"\n",
    "    Convert a base64 string to a PIL Image.\n",
    "    \n",
    "    Parameters:\n",
    "    - base64_str (str): Base64-encoded image string.\n",
    "    \n",
    "    Returns:\n",
    "    - img (PIL.Image): Decoded image.\n",
    "    \"\"\"\n",
    "    image_bytes = base64.b64decode(base64_str)\n",
    "    img = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "    img = np.array(img.convert('L'))  # Convert to grayscale\n",
    "    img_resized = cv2.resize(img, (size, size))\n",
    "    return img_resized.astype(np.float32)\n",
    "\n",
    "def compute_gradients(image):\n",
    "    \"\"\"\n",
    "    Compute image gradients using the Sobel operator.\n",
    "    (Gaussian derivatives can be used for more robustness.)\n",
    "    \"\"\"\n",
    "    grad_x = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    orientation = np.arctan2(grad_y, grad_x)\n",
    "    orientation = np.mod(orientation, np.pi)  # Map angles to [0, Ï€)\n",
    "    return magnitude, orientation\n",
    "\n",
    "def extract_local_descriptors(image, grid_size=(28, 28), patch_size_ratio=0.125,\n",
    "                              num_spatial_bins=4, num_orientation_bins=4):\n",
    "    \"\"\"\n",
    "    For each patch (sampled on a grid) in the image, subdivide it into\n",
    "    (num_spatial_bins x num_spatial_bins) cells and compute a histogram of \n",
    "    gradient orientations (with num_orientation_bins bins) for each cell.\n",
    "    Concatenate the histograms from all cells to yield a 64-dimensional descriptor.\n",
    "    Returns an array of descriptors (one per patch).\n",
    "    \"\"\"\n",
    "    magnitude, orientation = compute_gradients(image)\n",
    "    h, w = image.shape\n",
    "    descriptors = []\n",
    "    # Generate grid points (centers) for patches\n",
    "    xs = np.linspace(0, w-1, grid_size[1], dtype=int)\n",
    "    ys = np.linspace(0, h-1, grid_size[0], dtype=int)\n",
    "    patch_size = int(patch_size_ratio * w)  # e.g., ~32 pixels for a 256x256 image\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    for y in ys:\n",
    "        for x in xs:\n",
    "            # Define patch boundaries (with border checks)\n",
    "            x1 = max(x - half_patch, 0)\n",
    "            x2 = min(x + half_patch, w)\n",
    "            y1 = max(y - half_patch, 0)\n",
    "            y2 = min(y + half_patch, h)\n",
    "            patch_mag = magnitude[y1:y2, x1:x2]\n",
    "            patch_orient = orientation[y1:y2, x1:x2]\n",
    "            # Determine cell sizes within the patch\n",
    "            cell_h = (y2 - y1) // num_spatial_bins\n",
    "            cell_w = (x2 - x1) // num_spatial_bins\n",
    "            descriptor = []\n",
    "            # Iterate over cells\n",
    "            for i in range(num_spatial_bins):\n",
    "                for j in range(num_spatial_bins):\n",
    "                    cy1 = y1 + i * cell_h\n",
    "                    cy2 = cy1 + cell_h\n",
    "                    cx1 = x1 + j * cell_w\n",
    "                    cx2 = cx1 + cell_w\n",
    "                    # Extract cell region\n",
    "                    cell_orient = patch_orient[cy1 - y1:cy2 - y1, cx1 - x1:cx2 - x1]\n",
    "                    cell_mag = patch_mag[cy1 - y1:cy2 - y1, cx1 - x1:cx2 - x1]\n",
    "                    # Compute histogram for cell\n",
    "                    hist, _ = np.histogram(cell_orient, bins=num_orientation_bins, \n",
    "                                           range=(0, np.pi), weights=cell_mag)\n",
    "                    descriptor.extend(hist)\n",
    "            descriptor = np.array(descriptor, dtype=np.float32)\n",
    "            norm_val = np.linalg.norm(descriptor)\n",
    "            if norm_val > 0:\n",
    "                descriptor /= norm_val\n",
    "            descriptors.append(descriptor)\n",
    "    return np.array(descriptors)  # Shape: (num_patches, 64)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Compute Global Image Feature (Histogram of Visual Words)\n",
    "# ----------------------------\n",
    "\n",
    "def quantize_descriptors(descriptors, vocabulary):\n",
    "    \"\"\"\n",
    "    Quantize each 64-D descriptor to the nearest word in the vocabulary.\n",
    "    Returns a normalized histogram (global feature vector) of dimension equal to vocab_size.\n",
    "    \"\"\"\n",
    "    from scipy.spatial.distance import cdist\n",
    "    distances = cdist(descriptors, vocabulary, metric='euclidean')\n",
    "    assignments = np.argmin(distances, axis=1)\n",
    "    vocab_size = vocabulary.shape[0]\n",
    "    hist = np.zeros(vocab_size, dtype=np.float32)\n",
    "    for idx in assignments:\n",
    "        hist[idx] += 1\n",
    "    if hist.sum() > 0:\n",
    "        hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "def soft_quantize_descriptors(descriptors, vocabulary, sigma=0.3):\n",
    "    \"\"\"\n",
    "    For each descriptor, compute Gaussian weighted contributions to each vocabulary center,\n",
    "    then sum up contributions into a histogram.\n",
    "    \"\"\"\n",
    "    distances = cdist(descriptors, vocabulary, metric='euclidean')\n",
    "    # Compute weights using a Gaussian kernel\n",
    "    weights = np.exp(-distances*2 / (2 * sigma*2))\n",
    "    # Normalize weights for each descriptor\n",
    "    weights /= weights.sum(axis=1, keepdims=True)\n",
    "    # Sum contributions over all descriptors to obtain histogram\n",
    "    hist = weights.sum(axis=0)\n",
    "    if hist.sum() > 0:\n",
    "        hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "def extract_image_feature(image, vocabulary):\n",
    "    \"\"\"\n",
    "    For a given image, extract local descriptors and compute a global 500-D feature \n",
    "    vector by quantizing the descriptors with the visual vocabulary.\n",
    "    \"\"\"\n",
    "    descriptors = soft_quantize_descriptors(image)\n",
    "    feature_vector = quantize_descriptors(descriptors, vocabulary)\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "# Load the vocabulary\n",
    "vocab_path = \"..\\\\skribix_v2\\\\feature extraction\\\\vocabulary.npy\"\n",
    "\n",
    "vocabulary = np.load(vocab_path)\n",
    "\n",
    "knn_model_path = \"..\\\\skribix_v2\\\\knn model\\\\knn_model.joblib\"\n",
    "# Load the Knn model\n",
    "knn_model = joblib.load(knn_model_path)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "\n",
    "    if 'image' not in data:\n",
    "        return jsonify({'error': 'No image data provided'}), 400\n",
    "\n",
    "    try:\n",
    "        # Remove the data URL prefix (e.g. \"data:image/png;base64,...\")\n",
    "        base64_data = data['image'].split(\",\")[1]\n",
    "        # image_bytes = base64.b64decode(base64_data)\n",
    "        # image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "\n",
    "        # # Resize and preprocess\n",
    "        # image = image.resize((256, 256))  # adjust as per model\n",
    "        # image_array = np.array(image)\n",
    "        # preprocessed_image = img_preprocessing(image_array)\n",
    "\n",
    "        # input_data = np.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "        sample_image = base64_to_image(base64_data)\n",
    "        feature_vector = extract_image_feature(sample_image, vocabulary)\n",
    "\n",
    "        # predictions = model.predict(input_data)\n",
    "        # results = predictions.tolist()\n",
    "\n",
    "        # return jsonify({'predictions': results})\n",
    "        prediction = knn_model.predict([feature_vector])\n",
    "\n",
    "        return jsonify({'prediction': prediction})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=7001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
