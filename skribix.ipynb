{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, output_size=(256, 256)):\n",
    "    # Load the image in grayscale mode\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(\"Error loading image:\", image_path)\n",
    "        return None\n",
    "\n",
    "    # Binarize the image using Otsu's thresholding\n",
    "    # This converts the image to a binary image (0 and 255)\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Optionally, you can perform additional morphological operations here\n",
    "    # For example, if you want to remove noise or fill small gaps:\n",
    "    # kernel = np.ones((3, 3), np.uint8)\n",
    "    # binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Normalize the image size by resizing\n",
    "    binary_resized = cv2.resize(binary, output_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return binary_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(input_folder, output_folder, output_size=(256, 256)):\n",
    "    # Create the output directory if it does not exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get list of image files in the input folder (assuming PNG images)\n",
    "    image_files = glob(os.path.join(input_folder, \"**\", \"*.png\"), recursive=True)\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in {input_folder}.\")\n",
    "    \n",
    "    # Process each image\n",
    "    for image_path in image_files:\n",
    "        preprocessed = preprocess_image(image_path, output_size)\n",
    "        if preprocessed is not None:\n",
    "            filename = os.path.basename(image_path)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            cv2.imwrite(output_path, preprocessed)\n",
    "    \n",
    "    print(\"Preprocessing complete. Preprocessed images saved to:\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images in ./sketches.\n",
      "Preprocessing complete. Preprocessed images saved to: ./processed_sketches\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the paths to your dataset directory and the directory to save processed images.\n",
    "    input_folder = \"./sketches\"       \n",
    "    output_folder = \"./processed_sketches\"  \n",
    "    \n",
    "    output_size = (256, 256)\n",
    "    \n",
    "    process_dataset(input_folder, output_folder, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation of pixels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images normalized and saved in 'normalized_sketches'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# defining path for input and output folders!\n",
    "FOLDER_PATH = \"processed_sketches\"\n",
    "OUTPUT_FOLDER = \"normalized_sketches\" \n",
    "\n",
    "# ensures output folder exists\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "def normalize_images(folder_path, output_folder):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Read image in grayscale\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Skipping {filename} (not a valid image)\")\n",
    "            continue\n",
    "\n",
    "        # Normalize pixel values to range [0,1]\n",
    "        img_normalized = img.astype(\"float32\") / 255.0\n",
    "        # Convert back to 8-bit for saving as PNG/JPG\n",
    "        img_uint8 = (img_normalized * 255).astype(\"uint8\")\n",
    "        # Save the normalized image\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, img_uint8)\n",
    "\n",
    "    print(f\"All images normalized and saved in '{output_folder}'\")\n",
    "\n",
    "# Run fucntion\n",
    "normalize_images(FOLDER_PATH, OUTPUT_FOLDER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Mean Shift Clustering Algorithm**\n",
    "\n",
    "Mean Shift is a **centroid-based** clustering algorithm. It iteratively shifts data points towards denser regions (clusters move towards higher density), making it useful for identifying clusters **without predefining the number of clusters**, which suits best for image classification. It is based on **Kernel Density Estimation (KDE)** and moves points towards higher-density areas.\n",
    "\n",
    "### **Steps of Mean Shift:**\n",
    "1. **Initialize Centroids:**  \n",
    "   Each data point is considered a potential cluster center.\n",
    "2. **Compute Mean Shift Vector:**  \n",
    "   - For each centroid, find all points within a given bandwidth (a neighborhood around the centroid).  \n",
    "   - Compute the mean (center of mass) of these points.  \n",
    "   - Shift the centroid towards this mean.\n",
    "3. **Repeat Until Convergence:**  \n",
    "   - Continue shifting centroids until their movement is below a threshold.  \n",
    "   - Merge centroids that converge to the same location.\n",
    "4. **Assign Clusters:**  \n",
    "   - After convergence, each data point is assigned to the nearest centroid.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Working of Mean Shift**\n",
    "- **Kernel Density Estimation (KDE):** Mean Shift estimates the density distribution of data points to determine cluster centers.\n",
    "- **Bandwidth Selection:** The **bandwidth parameter** defines how large the search neighborhood is.  \n",
    "  - A **small bandwidth** results in more clusters.  \n",
    "  - A **large bandwidth** merges clusters together.  \n",
    "- **Adaptive Clustering:** Unlike K-Means, Mean Shift does not assume clusters are spherical and can detect arbitrarily shaped clusters.\n",
    "\n",
    "---\n",
    "\n",
    "# **Mathematics Behind Mean Shift Clustering**\n",
    "\n",
    "Mean Shift is a **density-based clustering algorithm** that moves data points towards regions of higher density based on **Kernel Density Estimation (KDE)**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Kernel Density Estimation (KDE)**  \n",
    "The Mean Shift algorithm uses **KDE** to estimate the **density of data points**. The density function at a point \\( x \\) is given by:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{n h^d} \\sum_{i=1}^{n} K \\left( \\frac{x - x_i}{h} \\right)\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- \\( f(x) \\) is the estimated density at \\( x \\).  \n",
    "- \\( n \\) is the number of data points.  \n",
    "- \\( h \\) is the **bandwidth** (window size).  \n",
    "- \\( d \\) is the number of dimensions in the dataset.  \n",
    "- \\( K(\\cdot) \\) is the **kernel function** that defines the weight of nearby points.\n",
    "- \\( x_i \\) are the data points in the dataset.  \n",
    "\n",
    "### **Common Kernel Functions**\n",
    "Mean Shift typically uses a **Gaussian kernel**, defined as:\n",
    "\n",
    "$$\n",
    "K(x) = e^{-\\frac{||x||^2}{2}}\n",
    "$$\n",
    "\n",
    "Other kernels include **Epanechnikov, Uniform, and Triangular kernels**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Mean Shift Vector**\n",
    "The Mean Shift vector is computed as the **weighted mean of points within the bandwidth**. Mathematically, it is defined as:\n",
    "\n",
    "$$\n",
    "m(x) = \\frac{\\sum_{i=1}^{n} x_i K \\left( \\frac{x - x_i}{h} \\right)}{\\sum_{i=1}^{n} K \\left( \\frac{x - x_i}{h} \\right)}\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- \\( m(x) \\) is the new mean (shifted point).  \n",
    "- The numerator computes a weighted sum of all points within the bandwidth.  \n",
    "- The denominator normalizes the weights.\n",
    "\n",
    "Each point \\( x \\) is shifted iteratively using:\n",
    "\n",
    "$$\n",
    "x_{t+1} = m(x_t)\n",
    "$$\n",
    "\n",
    "until convergence (i.e., when the shifts become negligible).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Bandwidth Selection**\n",
    "The choice of **bandwidth \\( h \\)** is crucial for Mean Shift.  \n",
    "- A **small bandwidth** creates **more clusters** (over-segmentation).  \n",
    "- A **large bandwidth** merges clusters (under-segmentation).  \n",
    "- A common method to estimate bandwidth is **Scott’s Rule** or **Silverman’s Rule**:\n",
    "\n",
    "$$\n",
    "h = \\left( \\frac{4}{d+2} \\right)^{\\frac{1}{d+4}} n^{-\\frac{1}{d+4}}\n",
    "$$\n",
    "\n",
    "where \\( d \\) is the number of dimensions and \\( n \\) is the number of samples.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Convergence Criteria**\n",
    "The algorithm stops when:\n",
    "\n",
    "$$\n",
    "||m(x_t) - x_t|| < \\epsilon\n",
    "$$\n",
    "\n",
    "where **\\(epsilon)** is a small threshold.\n",
    "\n",
    "This ensures that centroids **do not move significantly** between iterations.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
